{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-25T14:26:30.975729Z",
     "end_time": "2023-04-25T14:26:35.007710Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 定义数据增强的transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# 加载CIFAR10数据集\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# 定义训练和测试集的数据加载器\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T14:26:35.012654Z",
     "end_time": "2023-04-25T14:26:36.685660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 定义GoogleNet模型\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, ch1x1, ch3x3_reduce, ch3x3, ch5x5_reduce, ch5x5, pool_proj):\n",
    "        super(Inception, self).__init__()\n",
    "        # 1x1 convolution branch\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch1x1, kernel_size=1),\n",
    "            nn.BatchNorm2d(ch1x1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # 1x1/3x3 convolutions branch\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch3x3_reduce, kernel_size=1),\n",
    "            nn.BatchNorm2d(ch3x3_reduce),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch3x3_reduce, ch3x3, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(ch3x3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # 1x1/5x5 convolutions branch\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, ch5x5_reduce, kernel_size=1),\n",
    "            nn.BatchNorm2d(ch5x5_reduce),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch5x5_reduce, ch5x5, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(ch5x5),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # 3x3 pool/1x1 convolutions branch\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, pool_proj, kernel_size=1),\n",
    "            nn.BatchNorm2d(pool_proj),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1(x)\n",
    "        branch2 = self.branch2(x)\n",
    "        branch3 = self.branch3(x)\n",
    "        branch4 = self.branch4(x)\n",
    "        outputs = [branch1, branch2, branch3, branch4]\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(GoogleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T14:26:36.685660Z",
     "end_time": "2023-04-25T14:26:36.757570Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 初始化模型、损失函数和优化器\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GoogleNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T14:26:36.762555Z",
     "end_time": "2023-04-25T14:26:38.448606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 5.4275, Train Acc: 0.2744, Test Loss: 5.4275, Test Acc: 0.2744\n",
      "Epoch 2: Train Loss: 2.1257, Train Acc: 0.3197, Test Loss: 2.1257, Test Acc: 0.3197\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 2\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = running_corrects / len(train_loader.dataset)\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_acc.append(epoch_acc)\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(test_loader.dataset)\n",
    "    epoch_acc = running_corrects / len(test_loader.dataset)\n",
    "    test_loss.append(epoch_loss)\n",
    "    test_acc.append(epoch_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}: Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, Test Loss: {epoch_loss:.4f}, Test Acc: {epoch_acc:.4f}')\n",
    "\n",
    "# 绘制训练/测试的损失和准确率图表\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(test_loss, label='Testing Loss')\n",
    "plt.plot(train_acc, label='Training Accuracy')\n",
    "plt.plot(test_acc, label='Testing Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T14:26:38.414405Z",
     "end_time": "2023-04-25T14:28:33.329195Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(train_loss, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining Loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(test_loss, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTesting Loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_acc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTraining Accuracy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(test_acc, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTesting Accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mlegend()\n",
      "File \u001B[1;32mD:\\Environment\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\matplotlib\\pyplot.py:2812\u001B[0m, in \u001B[0;36mplot\u001B[1;34m(scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2810\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mplot)\n\u001B[0;32m   2811\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot\u001B[39m(\u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, scaley\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m-> 2812\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m gca()\u001B[38;5;241m.\u001B[39mplot(\n\u001B[0;32m   2813\u001B[0m         \u001B[38;5;241m*\u001B[39margs, scalex\u001B[38;5;241m=\u001B[39mscalex, scaley\u001B[38;5;241m=\u001B[39mscaley,\n\u001B[0;32m   2814\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m: data} \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Environment\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001B[0m, in \u001B[0;36mAxes.plot\u001B[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1445\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1446\u001B[0m \u001B[38;5;124;03mPlot y versus x as lines and/or markers.\u001B[39;00m\n\u001B[0;32m   1447\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1685\u001B[0m \u001B[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001B[39;00m\n\u001B[0;32m   1686\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1687\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m cbook\u001B[38;5;241m.\u001B[39mnormalize_kwargs(kwargs, mlines\u001B[38;5;241m.\u001B[39mLine2D)\n\u001B[1;32m-> 1688\u001B[0m lines \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_lines(\u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39mdata, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)]\n\u001B[0;32m   1689\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m lines:\n\u001B[0;32m   1690\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_line(line)\n",
      "File \u001B[1;32mD:\\Environment\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001B[0m, in \u001B[0;36m_process_plot_var_args.__call__\u001B[1;34m(self, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m     this \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m0\u001B[39m],\n\u001B[0;32m    310\u001B[0m     args \u001B[38;5;241m=\u001B[39m args[\u001B[38;5;241m1\u001B[39m:]\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_plot_args\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mambiguous_fmt_datakey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mambiguous_fmt_datakey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Environment\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\matplotlib\\axes\\_base.py:496\u001B[0m, in \u001B[0;36m_process_plot_var_args._plot_args\u001B[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001B[0m\n\u001B[0;32m    494\u001B[0m     y \u001B[38;5;241m=\u001B[39m _check_1d(xy[\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m    495\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 496\u001B[0m     x, y \u001B[38;5;241m=\u001B[39m \u001B[43mindex_of\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxy\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes\u001B[38;5;241m.\u001B[39mxaxis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    499\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes\u001B[38;5;241m.\u001B[39mxaxis\u001B[38;5;241m.\u001B[39mupdate_units(x)\n",
      "File \u001B[1;32mD:\\Environment\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1656\u001B[0m, in \u001B[0;36mindex_of\u001B[1;34m(y)\u001B[0m\n\u001B[0;32m   1654\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1656\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43m_check_1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1657\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (np\u001B[38;5;241m.\u001B[39mVisibleDeprecationWarning, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m   1658\u001B[0m     \u001B[38;5;66;03m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001B[39;00m\n\u001B[0;32m   1659\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Environment\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1348\u001B[0m, in \u001B[0;36m_check_1d\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   1342\u001B[0m \u001B[38;5;66;03m# plot requires `shape` and `ndim`.  If passed an\u001B[39;00m\n\u001B[0;32m   1343\u001B[0m \u001B[38;5;66;03m# object that doesn't provide them, then force to numpy array.\u001B[39;00m\n\u001B[0;32m   1344\u001B[0m \u001B[38;5;66;03m# Note this will strip unit information.\u001B[39;00m\n\u001B[0;32m   1345\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1346\u001B[0m         \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1347\u001B[0m         \u001B[38;5;28mlen\u001B[39m(x\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m-> 1348\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43matleast_1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1349\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1350\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36matleast_1d\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32mD:\\Environment\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\numpy\\core\\shape_base.py:65\u001B[0m, in \u001B[0;36matleast_1d\u001B[1;34m(*arys)\u001B[0m\n\u001B[0;32m     63\u001B[0m res \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ary \u001B[38;5;129;01min\u001B[39;00m arys:\n\u001B[1;32m---> 65\u001B[0m     ary \u001B[38;5;241m=\u001B[39m \u001B[43masanyarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mary\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ary\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     67\u001B[0m         result \u001B[38;5;241m=\u001B[39m ary\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32mD:\\Environment\\Anaconda3\\envs\\pytorch39\\lib\\site-packages\\torch\\tensor.py:630\u001B[0m, in \u001B[0;36mTensor.__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(Tensor\u001B[38;5;241m.\u001B[39m__array__, relevant_args, \u001B[38;5;28mself\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    629\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 630\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mTypeError\u001B[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
